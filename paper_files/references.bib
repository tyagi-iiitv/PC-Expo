
@misc{noauthor_parallel_nodate,
	title = {Parallel {Coordinates} {Dimension} {Reorderings} {Implementation}},
	url = {https://subspace.dbvis.de/pcp/},
	urldate = {2022-01-24},
	file = {Parallel Coordinates Dimension Reorderings Implementation:C\:\\Users\\anjul\\Zotero\\storage\\VJDB7HW5\\pcp.html:text/html},
}

@book{peltonen_parallel_2017,
	title = {Parallel {Coordinate} {Plots} for {Neighbor} {Retrieval}},
	abstract = {Parallel Coordinate Plots (PCPs) are a prominent approach to visualize the full feature set of high-dimensional vectorial data, either standalone or complementing other visualizations like scatter plots. Optimization of PCPs has concentrated on ordering and positioning of the coordinate axes based on various statistical criteria. We introduce a new method to construct PCPs that are directly optimized to support a common data analysis task: analyzing neighborhood relationships of data items within each coordinate axis and across the axes. We optimize PCPs on 1D lines or 2D planes for accurate viewing of neighborhood relationships among data items, measured as an information retrieval task. Both the similarity measurement between axes and the axis positions are directly optimized for accurate neighbor retrieval. The resulting method, called Parallel Coordinate Plots for Neighbor Retrieval (PCP-NR), achieves better information retrieval performance than traditional PCPs in experiments.},
	author = {Peltonen, Jaakko and Lin, Ziyuan},
	month = feb,
	year = {2017},
	doi = {10.5220/0006097400400051},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\Y5FUVRCI\\Peltonen and Lin - 2017 - Parallel Coordinate Plots for Neighbor Retrieval.pdf:application/pdf},
}

@inproceedings{dubska_pclines_2011,
	address = {Colorado Springs, CO, USA},
	title = {{PClines} \&\#x2014; {Line} detection using parallel coordinates},
	isbn = {978-1-4577-0394-2},
	url = {http://ieeexplore.ieee.org/document/5995501/},
	doi = {10.1109/CVPR.2011.5995501},
	abstract = {Detection of lines in raster images is often performed using Hough transform. This paper presents a new parameterization of lines and a modiﬁcation of the Hough transform – PClines. PClines are based on parallel coordinates, a coordinate system used mostly or solely for high-dimensional data visualization. The PClines algorithm is described in the paper; its accuracy is evaluated numerically and compared to the commonly used line detectors based on the Hough transform. The results show that PClines outperform the existing approaches in terms of accuracy. Besides, PClines are computationally extremely efﬁcient, require no ﬂoating-point operations, and can be easily accelerated by different hardware architectures.},
	language = {en},
	urldate = {2022-01-24},
	booktitle = {{CVPR} 2011},
	publisher = {IEEE},
	author = {Dubska, Marketa and Herout, Adam and Havel, Jiri},
	month = jun,
	year = {2011},
	pages = {1489--1494},
	file = {Dubska et al. - 2011 - PClines &#x2014\; Line detection using parallel coo.pdf:C\:\\Users\\anjul\\Zotero\\storage\\Q5RKBQXY\\Dubska et al. - 2011 - PClines &#x2014\; Line detection using parallel coo.pdf:application/pdf},
}

@article{bresson_transformer_2021,
	title = {The {Transformer} {Network} for the {Traveling} {Salesman} {Problem}},
	url = {http://arxiv.org/abs/2103.03012},
	abstract = {The Traveling Salesman Problem (TSP) is the most popular and most studied combinatorial problem, starting with von Neumann in 1951. It has driven the discovery of several optimization techniques such as cutting planes, branch-and-bound, local search, Lagrangian relaxation, and simulated annealing. The last five years have seen the emergence of promising techniques where (graph) neural networks have been capable to learn new combinatorial algorithms. The main question is whether deep learning can learn better heuristics from data, i.e. replacing human-engineered heuristics? This is appealing because developing algorithms to tackle efficiently NP-hard problems may require years of research, and many industry problems are combinatorial by nature. In this work, we propose to adapt the recent successful Transformer architecture originally developed for natural language processing to the combinatorial TSP. Training is done by reinforcement learning, hence without TSP training solutions, and decoding uses beam search. We report improved performances over recent learned heuristics with an optimal gap of 0.004\% for TSP50 and 0.39\% for TSP100.},
	urldate = {2022-01-24},
	journal = {arXiv:2103.03012 [cs]},
	author = {Bresson, Xavier and Laurent, Thomas},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.03012},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\76HI2HKV\\Bresson and Laurent - 2021 - The Transformer Network for the Traveling Salesman.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\RG84DKXI\\2103.html:text/html},
}

@article{hurley_pairwise_2010,
	title = {Pairwise {Display} of {High}-{Dimensional} {Information} via {Eulerian} {Tours} and {Hamiltonian} {Decompositions}},
	volume = {19},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.09136},
	doi = {10.1198/jcgs.2010.09136},
	abstract = {A graph theoretic approach is taken to the component order problem in the layout of statistical graphics. Eulerian tours and Hamiltonian decompositions of complete graphs are used to ameliorate order eﬀects in statistical graphics. Similar traversals of edge weighted graphs are used to amplify the visual eﬀect of selected salient features in the data. Relevant graph theory is summarized and classic algorithms are tailored to this problem. Graphics for multiple comparisons are reviewed and a new display developed that is based on graph traversal. Interaction plots are improved and new ones proposed. Improved star glyph displays of multivariate data are described. Parallel coordinate displays tailored to particular features of the data are developed. The methods and new graphical displays are made available as an R package.},
	language = {en},
	number = {4},
	urldate = {2022-01-24},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Hurley, C. B. and Oldford, R. W.},
	month = jan,
	year = {2010},
	pages = {861--886},
	file = {Hurley and Oldford - 2010 - Pairwise Display of High-Dimensional Information v.pdf:C\:\\Users\\anjul\\Zotero\\storage\\7SCKIWWJ\\Hurley and Oldford - 2010 - Pairwise Display of High-Dimensional Information v.pdf:application/pdf},
}

@article{johansson_evaluation_2015,
	title = {Evaluation of {Parallel} {Coordinates}: {Overview}, {Categorization} and {Guidelines} for {Future} {Research}},
	volume = {22},
	shorttitle = {Evaluation of {Parallel} {Coordinates}},
	doi = {10.1109/TVCG.2015.2466992},
	abstract = {The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Johansson, Jimmy and Forsell, Camilla},
	month = nov,
	year = {2015},
	pages = {1--1},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\P7INGFEP\\Johansson and Forsell - 2015 - Evaluation of Parallel Coordinates Overview, Cate.pdf:application/pdf},
}

@article{ellis_taxonomy_2007,
	title = {A {Taxonomy} of {Clutter} {Reduction} for {Information} {Visualisation}},
	volume = {13},
	doi = {10.1109/TVCG.2007.70535},
	abstract = {Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Ellis, Geoffrey and Dix, Alan},
	month = dec,
	year = {2007},
	pages = {1216--23},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\Z5AQM7JJ\\Ellis and Dix - 2007 - A Taxonomy of Clutter Reduction for Information Vi.pdf:application/pdf},
}

@article{johansson_interactive_2009,
	title = {Interactive {Dimensionality} {Reduction} {Through} {User}-defined {Combinations} of {Quality} {Metrics}},
	volume = {15},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2009.153},
	abstract = {Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Johansson, Sara and Johansson, Jimmy},
	month = nov,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data analysis, Data visualization, Displays, Humans, Information Visualization, Lenses, Monitoring, Multidimensional Scaling, Parallel Coordinates, Product development, Scattering, Scatterplots, Weight control},
	pages = {993--1000},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\anjul\\Zotero\\storage\\JSX8U6HC\\5290704.html:text/html},
}

@article{tatu_automated_2011,
	title = {Automated {Analytical} {Methods} to {Support} {Visual} {Exploration} of {High}-{Dimensional} {Data}},
	volume = {17},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2010.242},
	abstract = {Visual exploration of multivariate data typically requires projection onto lower dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non-class-based scatterplots and parallel coordinates visualizations. The proposed analysis methods are evaluated on different data sets.},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Tatu, Andrada and Albuquerque, Georgia and Eisemann, Martin and Bak, Peter and Theisel, Holger and Magnor, Marcus and Keim, Daniel},
	month = may,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data visualization, Coordinate measuring machines, Correlation, Density measurement, Dimensionality reduction, parallel coordinates., Pixel, quality measures, Rotation measurement, scatterplots, Visualization},
	pages = {584--597},
	file = {Submitted Version:C\:\\Users\\anjul\\Zotero\\storage\\VREVVX2A\\Tatu et al. - 2011 - Automated Analytical Methods to Support Visual Exp.pdf:application/pdf},
}

@inproceedings{peng_clutter_2004,
	title = {Clutter {Reduction} in {Multi}-{Dimensional} {Data} {Visualization} {Using} {Dimension} {Reordering}},
	doi = {10.1109/INFVIS.2004.15},
	abstract = {Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer’s understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization’s expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display.},
	booktitle = {{IEEE} {Symposium} on {Information} {Visualization}},
	author = {Peng, Wei and Ward, M.O. and Rundensteiner, E.A.},
	month = oct,
	year = {2004},
	note = {ISSN: 1522-404X},
	keywords = {Data visualization, Displays, Scattering, Chromium, Computer science, dimension order, Gain measurement, Multidimensional systems, Multidimensional visualization, Pattern recognition, Polarization, User interfaces, visual clutter, visual structure},
	pages = {89--96},
	file = {Submitted Version:C\:\\Users\\anjul\\Zotero\\storage\\H3XRWNN6\\Peng et al. - 2004 - Clutter Reduction in Multi-Dimensional Data Visual.pdf:application/pdf},
}

@article{pomerenke_slope-dependent_2019,
	title = {Slope-{Dependent} {Rendering} of {Parallel} {Coordinates} to {Reduce} {Density} {Distortion} and {Ghost} {Clusters}},
	url = {http://arxiv.org/abs/1908.00500},
	doi = {10.1109/VISUAL.2019.8933706},
	abstract = {Parallel coordinates are a popular technique to visualize multi-dimensional data. However, they face a significant problem influencing the perception and interpretation of patterns. The distance between two parallel lines differs based on their slope. Vertical lines are rendered longer and closer to each other than horizontal lines. This problem is inherent in the technique and has two main consequences: (1) clusters which have a steep slope between two axes are visually more prominent than horizontal clusters. (2) Noise and clutter can be perceived as clusters, as a few parallel vertical lines visually emerge as a ghost cluster. Our paper makes two contributions: First, we formalize the problem and show its impact. Second, we present a novel technique to reduce the effects by rendering the polylines of the parallel coordinates based on their slope: horizontal lines are rendered with the default width, lines with a steep slope with a thinner line. Our technique avoids density distortions of clusters, can be computed in linear time, and can be added on top of most parallel coordinate variations. To demonstrate the usefulness, we show examples and compare them to the classical rendering.},
	urldate = {2022-01-24},
	journal = {2019 IEEE Visualization Conference (VIS)},
	author = {Pomerenke, David and Dennig, Frederik L. and Keim, Daniel A. and Fuchs, Johannes and Blumenschein, Michael},
	month = oct,
	year = {2019},
	note = {arXiv: 1908.00500},
	keywords = {Computer Science - Graphics},
	pages = {86--90},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\AE8RQFDQ\\Pomerenke et al. - 2019 - Slope-Dependent Rendering of Parallel Coordinates .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\3X3ZABIX\\1908.html:text/html},
}

@article{blumenschein_evaluating_2020,
	title = {Evaluating {Reordering} {Strategies} for {Cluster} {Identification} in {Parallel} {Coordinates}},
	volume = {39},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14000},
	doi = {10.1111/cgf.14000},
	abstract = {The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users’ confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.},
	language = {en},
	number = {3},
	urldate = {2022-01-24},
	journal = {Computer Graphics Forum},
	author = {Blumenschein, Michael and Zhang, Xuan and Pomerenke, David and Keim, Daniel A. and Fuchs, Johannes},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14000},
	keywords = {• Human-centered computing → Empirical studies in visualization, CCS Concepts},
	pages = {537--549},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\I5DV269B\\Blumenschein et al. - 2020 - Evaluating Reordering Strategies for Cluster Ident.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\8XI8DNK6\\cgf.html:text/html},
}

@article{dasgupta_pargnostics_2010,
	title = {Pargnostics: {Screen}-{Space} {Metrics} for {Parallel} {Coordinates}},
	volume = {16},
	issn = {1077-2626},
	shorttitle = {Pargnostics},
	url = {http://ieeexplore.ieee.org/document/5613439/},
	doi = {10.1109/TVCG.2010.184},
	abstract = {Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem.},
	language = {en},
	number = {6},
	urldate = {2022-01-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Dasgupta, A and Kosara, R},
	month = nov,
	year = {2010},
	pages = {1017--1026},
	file = {Dasgupta and Kosara - 2010 - Pargnostics Screen-Space Metrics for Parallel Coo.pdf:C\:\\Users\\anjul\\Zotero\\storage\\U2K9XYID\\Dasgupta and Kosara - 2010 - Pargnostics Screen-Space Metrics for Parallel Coo.pdf:application/pdf},
}

@article{mcdonnell_illustrative_2008,
	title = {Illustrative {Parallel} {Coordinates}},
	volume = {27},
	issn = {01677055, 14678659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2008.01239.x},
	doi = {10.1111/j.1467-8659.2008.01239.x},
	abstract = {Illustrative parallel coordinates (IPC) is a suite of artistic rendering techniques for augmenting and improving parallel coordinate (PC) visualizations. IPC techniques can be used to convey a large amount of information about a multidimensional dataset in a small area of the screen through the following approaches: (a) edge-bundling through splines; (b) visualization of “branched ” clusters to reveal the distribution of the data; (c) opacity-based hints to show cluster density; (d) opacity and shading effects to illustrate local line density on the parallel axes; and (e) silhouettes, shadows and halos to help the eye distinguish between overlapping clusters. Thus, the primary goal of this work is to convey as much information as possible in a manner that is aesthetically pleasing and easy to understand for non-experts.},
	language = {en},
	number = {3},
	urldate = {2022-02-24},
	journal = {Computer Graphics Forum},
	author = {McDonnell, K. T. and Mueller, K.},
	month = may,
	year = {2008},
	pages = {1031--1038},
	file = {McDonnell and Mueller - 2008 - Illustrative Parallel Coordinates.pdf:C\:\\Users\\anjul\\Zotero\\storage\\YM9RKYT2\\McDonnell and Mueller - 2008 - Illustrative Parallel Coordinates.pdf:application/pdf},
}

@article{hartigan_printer_1975,
	title = {Printer graphics for clustering},
	volume = {4},
	issn = {0094-9655},
	url = {https://doi.org/10.1080/00949657508810123},
	doi = {10.1080/00949657508810123},
	abstract = {One model for clusters in multivariate data is that the data are sampled from a density with many modes, one mode for each cluster. Methods of estimating multivariate densities may therefore be converted to clustering techniques, and clustering techniques may be helpful in estimating multivariate densities. Graphical techniques for representing clusters are closely related to multivariate histograms. Block histograms in two dimensions are constructed by finding a rectangle of minimum area containing a fixed number of points, deleting this rectangle and the points it contains, then finding another rectangle of minimum area containing a fixed number of points and so on. These histograms are simple visual representations of a density estimate in two dimensions. Analogous block histograms in many dimensions are useful but more difficult to represent graphically. A different approach represents each point by a box drawn in three or more dimensions. If the points are first ordered by some other clustering technique, the similarity of neighbouring boxes suggests or denies the presence of clusters.},
	number = {3},
	urldate = {2022-02-24},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Hartigan, J.A.},
	month = jan,
	year = {1975},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00949657508810123},
	pages = {187--213},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\RX2YQ5XN\\00949657508810123.html:text/html},
}

@inproceedings{berger_uncertainty-aware_2011,
	title = {Uncertainty-aware exploration of continuous parameter spaces using multivariate prediction},
	volume = {30},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Berger, Wolfgang and Piringer, Harald and Filzmoser, Peter and Gröller, Eduard},
	year = {2011},
	note = {Issue: 3},
	pages = {911--920},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\9KAHSM88\\j.1467-8659.2011.01940.html:text/html},
}

@inproceedings{piringer_hypermoval_2010,
	title = {Hypermoval: {Interactive} visual validation of regression models for real-time simulation},
	volume = {29},
	shorttitle = {Hypermoval},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Piringer, Harald and Berger, Wolfgang and Krasser, Jürgen},
	year = {2010},
	note = {Issue: 3},
	pages = {983--992},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\SZYIWQ2L\\j.1467-8659.2009.01684.html:text/html},
}

@inproceedings{tyagi_ice_2019,
	title = {{ICE}: {An} {Interactive} {Configuration} {Explorer} for {High} {Dimensional} {Categorical} {Parameter} {Spaces}},
	shorttitle = {{ICE}},
	doi = {10.1109/VAST47406.2019.8986923},
	abstract = {There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables, However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies.},
	booktitle = {2019 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Tyagi, Anjul and Cao, Zhen and Estro, Tyler and Zadok, Erez and Mueller, Klaus},
	month = oct,
	year = {2019},
	keywords = {Data visualization, Correlation, Visualization, Optimization, Data Clustering, High Dimensional Data, Ice, Illustrative Visualization, System performance, Throughput, User Interfaces},
	pages = {23--34},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\anjul\\Zotero\\storage\\IL6LSUN9\\8986923.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\78LNZB7Y\\Tyagi et al. - 2019 - ICE An Interactive Configuration Explorer for Hig.pdf:application/pdf},
}

@article{kosara_parallel_2006,
	title = {Parallel sets: {Interactive} exploration and visual analysis of categorical data},
	volume = {12},
	shorttitle = {Parallel sets},
	number = {4},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Kosara, Robert and Bendix, Fabian and Hauser, Helwig},
	year = {2006},
	note = {Publisher: IEEE},
	pages = {558--568},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\854FF8BG\\1634321.html:text/html},
}

@article{demir_multi-charts_2014,
	title = {Multi-charts for comparative 3d ensemble visualization},
	volume = {20},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Demir, Ismail and Dick, Christian and Westermann, Rüdiger},
	year = {2014},
	note = {Publisher: IEEE},
	pages = {2694--2703},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\EGVW7A35\\6875990.html:text/html},
}

@article{weissenbock_dynamic_2018,
	title = {Dynamic volume lines: {Visual} comparison of {3D} volumes through space-filling curves},
	volume = {25},
	shorttitle = {Dynamic volume lines},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Weissenböck, Johannes and Fröhler, Bernhard and Gröller, Eduard and Kastner, Johann and Heinzl, Christoph},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {1040--1049},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\CQ6PI8S6\\8440038.html:text/html},
}

@incollection{kruskal_relationship_1977,
	title = {The relationship between multidimensional scaling and clustering},
	booktitle = {Classification and clustering},
	publisher = {Elsevier},
	author = {Kruskal, Joseph},
	year = {1977},
	pages = {17--44},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\8X4BEKE3\\B9780127142500500061.html:text/html},
}

@inproceedings{kumar_task_2019,
	title = {Task classification model for visual fixation, exploration, and search},
	booktitle = {Proceedings of the 11th {ACM} {Symposium} on {Eye} {Tracking} {Research} \& {Applications}},
	author = {Kumar, Ayush and Tyagi, Anjul and Burch, Michael and Weiskopf, Daniel and Mueller, Klaus},
	year = {2019},
	pages = {1--4},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\N7SYHPN5\\Kumar et al. - 2019 - Task classification model for visual fixation, exp.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\IR7838ZN\\3314111.html:text/html},
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear dimensionality reduction by locally linear embedding},
	volume = {290},
	number = {5500},
	journal = {science},
	author = {Roweis, Sam T. and Saul, Lawrence K.},
	year = {2000},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {2323--2326},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\CIZB24I8\\science.290.5500.html:text/html;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\YP3HAFRU\\science.290.5500.html:text/html},
}

@article{ng_spectral_2001,
	title = {On spectral clustering: {Analysis} and an algorithm},
	volume = {14},
	shorttitle = {On spectral clustering},
	journal = {Advances in neural information processing systems},
	author = {Ng, Andrew and Jordan, Michael and Weiss, Yair},
	year = {2001},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\X7K7DD9U\\Ng et al. - 2001 - On spectral clustering Analysis and an algorithm.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\2LN9FV28\\801272ee79cfde7fa5960571fee36b9b-Abstract.html:text/html},
}

@article{van_der_maaten_visualizing_2008,
	title = {Visualizing data using t-{SNE}.},
	volume = {9},
	number = {11},
	journal = {Journal of machine learning research},
	author = {Van der Maaten, Laurens and Hinton, Geoffrey},
	year = {2008},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\6QMEVKHV\\Van der Maaten and Hinton - 2008 - Visualizing data using t-SNE..pdf:application/pdf},
}

@article{sedlmair_visual_2014,
	title = {Visual parameter space analysis: {A} conceptual framework},
	volume = {20},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sedlmair, Michael and Heinzl, Christoph and Bruckner, Stefan and Piringer, Harald and Möller, Torsten},
	year = {2014},
	note = {Publisher: IEEE},
	pages = {2161--2170},
}

@article{batagelj_pajek_2004,
	title = {Pajek: {Program} for analysis and visualization of large networks},
	journal = {Timeshift-The World in Twenty-Five Years: Ars Electronica},
	author = {Batagelj, Vladimir and Mrvar, Andrej},
	year = {2004},
	pages = {242--251},
}

@article{epskamp_qgraph_2012,
	title = {qgraph: {Network} visualizations of relationships in psychometric data},
	volume = {48},
	number = {4},
	journal = {Journal of Statistical Software},
	author = {Epskamp, Sacha and Cramer, Angélique OJ and Waldorp, Lourens J and Schmittmann, Verena D and Borsboom, Denny and {others}},
	year = {2012},
	pages = {1--18},
}

@article{zhang_visual_2015,
	title = {Visual correlation analysis of numerical and categorical data on the correlation map},
	volume = {21},
	number = {2},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Zhang, Zhiyuan and McDonnell, Kevin T and Zadok, Erez and Mueller, Klaus},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {289--303},
}

@article{wang_visual_2016,
	title = {The visual causality analyst: {An} interactive interface for causal reasoning},
	volume = {22},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Wang, Jun and Mueller, Klaus},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {230--239},
}

@article{zhao_clustering_2017,
	title = {Clustering ensemble selection for categorical data based on internal validity indices},
	volume = {69},
	journal = {Pattern Recognition},
	author = {Zhao, Xingwang and Liang, Jiye and Dang, Chuangyin},
	year = {2017},
	note = {Publisher: Elsevier},
	pages = {150--168},
}

@article{huang_extensions_1998,
	title = {Extensions to the k-means algorithm for clustering large data sets with categorical values},
	volume = {2},
	number = {3},
	journal = {Data mining and knowledge discovery},
	author = {Huang, Zhexue},
	year = {1998},
	note = {Publisher: Springer},
	pages = {283--304},
}

@article{chen_soft_2016,
	title = {Soft subspace clustering of categorical data with probabilistic distance},
	volume = {51},
	journal = {Pattern Recognition},
	author = {Chen, Lifei and Wang, Shengrui and Wang, Kaijun and Zhu, Jianping},
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {322--332},
}

@article{he_squeezer_2002,
	title = {Squeezer: an efficient algorithm for clustering categorical data},
	volume = {17},
	number = {5},
	journal = {Journal of Computer Science and Technology},
	author = {He, Zengyou and Xu, Xiaofei and Deng, Shengchun},
	year = {2002},
	note = {Publisher: Springer},
	pages = {611--624},
}

@inproceedings{barbara_coolcat_2002,
	title = {{COOLCAT}: an entropy-based algorithm for categorical clustering},
	booktitle = {Proceedings of the eleventh international conference on {Information} and knowledge management},
	publisher = {ACM},
	author = {Barbará, Daniel and Li, Yi and Couto, Julia},
	year = {2002},
	pages = {582--589},
}

@inproceedings{mika_fisher_1999,
	title = {Fisher discriminant analysis with kernels},
	booktitle = {Neural networks for signal processing {IX}: {Proceedings} of the 1999 {IEEE} signal processing society workshop (cat. no. 98th8468)},
	publisher = {Ieee},
	author = {Mika, Sebastian and Ratsch, Gunnar and Weston, Jason and Scholkopf, Bernhard and Mullers, Klaus-Robert},
	year = {1999},
	pages = {41--48},
}

@article{cheng_data_2016,
	title = {The data context map: {Fusing} data and attributes into a unified display},
	volume = {22},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Cheng, Shenghui and Mueller, Klaus},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {121--130},
}

@book{greenacre_correspondence_1984,
	title = {Correspondence analysis},
	publisher = {London: Academic Press},
	author = {Greenacre, Michael J},
	year = {1984},
}

@article{munzner_nested_2009,
	title = {A nested model for visualization design and validation},
	volume = {15},
	number = {6},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Munzner, Tamara},
	year = {2009},
	note = {Publisher: IEEE},
	pages = {921--928},
}

@article{harrower_colorbrewer_2003,
	title = {{ColorBrewer}. org: an online tool for selecting colour schemes for maps},
	volume = {40},
	number = {1},
	journal = {The Cartographic Journal},
	author = {Harrower, Mark and Brewer, Cynthia A},
	year = {2003},
	note = {Publisher: Taylor \& Francis},
	pages = {27--37},
}

@inproceedings{cao_performance_2017,
	title = {On the performance variation in modern storage stacks},
	booktitle = {15th \$\{\${USENIX}\$\}\$ {Conference} on {File} and {Storage} {Technologies} (\$\{\${FAST}\$\}\$ 17)},
	author = {Cao, Zhen and Tarasov, Vasily and Raman, Hari Prasath and Hildebrand, Dean and Zadok, Erez},
	year = {2017},
	pages = {329--344},
}

@article{hintze_violin_1998,
	title = {Violin plots: a box plot-density trace synergism},
	volume = {52},
	number = {2},
	journal = {The American Statistician},
	author = {Hintze, Jerry L and Nelson, Ray D},
	year = {1998},
	note = {Publisher: Taylor \& Francis},
	pages = {181--184},
}

@article{kampstra_beanplot_2008,
	title = {Beanplot: {A} boxplot alternative for visual comparison of distributions},
	author = {Kampstra, Peter and {others}},
	year = {2008},
}

@inproceedings{johnson_nih-nsf_2005,
	title = {{NIH}-{NSF} visualization research challenges report},
	publisher = {Institute of Electrical and Electronics Engineers},
	author = {Johnson, Chris and Moorhead, Robert and Munzner, Tamara and Pfister, Hanspeter and Rheingans, Penny and Yoo, Terry S},
	year = {2005},
}

@article{bostock_d3_2011,
	title = {D\${\textasciicircum}3\$ data-driven documents},
	volume = {17},
	number = {12},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
	year = {2011},
	note = {Publisher: IEEE},
	pages = {2301--2309},
}

@book{golub_matrix_2012,
	title = {Matrix computations},
	volume = {3},
	publisher = {JHU press},
	author = {Golub, Gene H and Van Loan, Charles F},
	year = {2012},
}

@article{tewarson_desirable_1973,
	title = {A desirable form for sparse matrices when computing their inverse in factored forms},
	volume = {11},
	number = {1},
	journal = {Computing},
	author = {Tewarson, Reginald P and Cheng, Kuo-Young},
	year = {1973},
	note = {Publisher: Springer},
	pages = {31--38},
}

@book{pissanetzky_sparse_1984,
	title = {Sparse {Matrix} {Technology}-electronic edition},
	publisher = {Academic Press},
	author = {Pissanetzky, Sergio},
	year = {1984},
}

@book{duff_direct_2017,
	title = {Direct methods for sparse matrices},
	publisher = {Oxford University Press},
	author = {Duff, Iain S and Erisman, Albert Maurice and Reid, John Ker},
	year = {2017},
}

@book{hettmansperger_robust_2010,
	title = {Robust nonparametric statistical methods},
	publisher = {CRC Press},
	author = {Hettmansperger, Thomas P and McKean, Joseph W},
	year = {2010},
}

@book{dabrera_nonparametrics_1975,
	title = {Nonparametrics: statistical methods based on ranks},
	publisher = {Holden-Day},
	author = {D'Abrera, HJM and Lehmann, EL},
	year = {1975},
}

@inproceedings{cao_towards_2018,
	title = {Towards better understanding of black-box auto-tuning: a comparative analysis for storage systems},
	booktitle = {2018 \$\{\${USENIX}\$\}\$ {Annual} {Technical} {Conference} (\$\{\${USENIX}\$\}\$\$\{\${ATC}\$\}\$ 18)},
	author = {Cao, Zhen and Tarasov, Vasily and Tiwari, Sachin and Zadok, Erez},
	year = {2018},
	pages = {893--907},
}

@inproceedings{tarasov_benchmarking_2011,
	title = {Benchmarking {File} {System} {Benchmarking}: {It}* {IS}* {Rocket} {Science}.},
	volume = {13},
	booktitle = {{HotOS}},
	author = {Tarasov, Vasily and Bhanage, Saumitra and Zadok, Erez and Seltzer, Margo},
	year = {2011},
	pages = {1--5},
}

@article{chen_vnfs_2017,
	title = {{vNFS}: maximizing {NFS} performance with compounds and vectorized {I}/{O}},
	volume = {13},
	number = {3},
	journal = {ACM Transactions on Storage (TOS)},
	author = {Chen, Ming and Bangera, Geetika Babu and Hildebrand, Dean and Jalia, Farhaan and Kuenning, Geoff and Nelson, Henry and Zadok, Erez},
	year = {2017},
	note = {Publisher: ACM},
	pages = {21},
}

@inproceedings{tyagi_road_2018,
	title = {Road {Accidents} in the {UK} ({Analysis} and {Visualization})},
	publisher = {IEEE VIS},
	author = {Tyagi, Anjul and Kumar, Ayush and Gandhi, Anshul and Mueller, Klaus},
	year = {2018},
}

@article{chen_survey_2015,
	title = {A survey of traffic data visualization},
	volume = {16},
	number = {6},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Chen, Wei and Guo, Fangzhou and Wang, Fei-Yue},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {2970--2984},
}

@article{wu_opinionseer_2010,
	title = {{OpinionSeer}: interactive visualization of hotel customer feedback},
	volume = {16},
	number = {6},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Wu, Yingcai and Wei, Furu and Liu, Shixia and Au, Norman and Cui, Weiwei and Zhou, Hong and Qu, Huamin},
	year = {2010},
	note = {Publisher: IEEE},
	pages = {1109--1118},
}

@article{elmqvist_rolling_2008,
	title = {Rolling the dice: {Multidimensional} visual exploration using scatterplot matrix navigation},
	volume = {14},
	number = {6},
	journal = {IEEE transactions on Visualization and Computer Graphics},
	author = {Elmqvist, Niklas and Dragicevic, Pierre and Fekete, Jean-Daniel},
	year = {2008},
	note = {Publisher: IEEE},
	pages = {1539--1148},
}

@inproceedings{keim_visual_2008,
	title = {Visual analytics: {Combining} automated discovery with interactive visualizations},
	booktitle = {International {Conference} on {Discovery} {Science}},
	publisher = {Springer},
	author = {Keim, Daniel A and Mansmann, Florian and Oelke, Daniela and Ziegler, Hartmut},
	year = {2008},
	pages = {2--14},
}

@inproceedings{van_aken_automatic_2017,
	title = {Automatic database management system tuning through large-scale machine learning},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Van Aken, Dana and Pavlo, Andrew and Gordon, Geoffrey J and Zhang, Bohan},
	year = {2017},
	pages = {1009--1024},
}

@article{trosset_visualizing_2005,
	title = {Visualizing correlation},
	volume = {14},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Trosset, Michael W},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	pages = {1--19},
}

@article{wang_perception-driven_2018,
	title = {A perception-driven approach to supervised dimensionality reduction for visualization},
	volume = {24},
	number = {5},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Wang, Yunhai and Feng, Kang and Chu, Xiaowei and Zhang, Jian and Fu, Chi-Wing and Sedlmair, Michael and Yu, Xiaohui and Chen, Baoquan},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {1828--1840},
}

@article{lehmann_optimal_2016,
	title = {Optimal sets of projections of high-dimensional data},
	volume = {22},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Lehmann, Dirk J and Theisel, Holger},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {609--618},
}

@inproceedings{meyer_four-level_2012,
	title = {The four-level nested model revisited: blocks and guidelines},
	booktitle = {Proceedings of the 2012 {BELIV} {Workshop}: {Beyond} {Time} and {Errors}-{Novel} {Evaluation} {Methods} for {Visualization}},
	publisher = {ACM},
	author = {Meyer, Miriah and Sedlmair, Michael and Munzner, Tamara},
	year = {2012},
	pages = {11},
}

@article{heuer_jr_analysis_1999,
	title = {Analysis of competing hypotheses},
	journal = {Psychology of Intelligence Analysis},
	author = {Heuer Jr, Richards J},
	year = {1999},
	note = {Publisher: Central Intelligence Agency},
	pages = {95--110},
}

@article{bergner_paraglide_2013,
	title = {Paraglide: {Interactive} parameter space partitioning for computer simulations},
	volume = {19},
	number = {9},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bergner, Steven and Sedlmair, Michael and Moller, Torsten and Abdolyousefi, Sareh Nabi and Saad, Ahmed},
	year = {2013},
	note = {Publisher: IEEE},
	pages = {1499--1512},
}

@inproceedings{booshehrian_vismon_2012,
	title = {Vismon: {Facilitating} analysis of trade-offs, uncertainty, and sensitivity in fisheries management decision making},
	volume = {31},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Booshehrian, Maryam and Möller, Torsten and Peterman, Randall M and Munzner, Tamara},
	year = {2012},
	note = {Issue: 3pt3},
	pages = {1235--1244},
}

@article{pretorius_visual_2015,
	title = {Visual parameter optimisation for biomedical image processing},
	volume = {16},
	number = {11},
	journal = {BMC bioinformatics},
	author = {Pretorius, AJ and Zhou, Yu and Ruddle, RA},
	year = {2015},
	note = {Publisher: BioMed Central},
	pages = {S9},
}

@misc{noauthor_kaggle_nodate,
	title = {Kaggle {HR} {Dataset}},
	url = {https://www.kaggle.com/rhuebner/human-resources-data-set},
}

@misc{noauthor_kaggle_nodate-1,
	title = {Kaggle {French} population dataset},
	url = {https://www.kaggle.com/etiennelq/french-employment-by-town},
}

@inproceedings{zhang_network-based_2012,
	title = {A network-based interface for the exploration of high-dimensional data spaces},
	booktitle = {2012 {IEEE} {Pacific} {Visualization} {Symposium}},
	publisher = {IEEE},
	author = {Zhang, Zhiyuan and McDonnell, Kevin T and Mueller, Klaus},
	year = {2012},
	pages = {17--24},
}

@article{cappers_exploring_2017,
	title = {Exploring multivariate event sequences using rules, aggregations, and selections},
	volume = {24},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Cappers, Bram CM and van Wijk, Jarke J},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {532--541},
}

@article{unger_understanding_2017,
	title = {Understanding a sequence of sequences: {Visual} exploration of categorical states in lake sediment cores},
	volume = {24},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Unger, Andrea and Dräger, Nadine and Sips, Mike and Lehmann, Dirk J},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {66--76},
}

@inproceedings{kandogan_star_2000,
	title = {Star coordinates: {A} multi-dimensional visualization technique with uniform treatment of dimensions},
	volume = {650},
	booktitle = {Proceedings of the {IEEE} {Information} {Visualization} {Symposium}},
	publisher = {Citeseer},
	author = {Kandogan, Eser},
	year = {2000},
	pages = {22},
}

@inproceedings{kandogan_visualizing_2001,
	title = {Visualizing multi-dimensional clusters, trends, and outliers using star coordinates},
	booktitle = {Proceedings of the seventh {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Kandogan, Eser},
	year = {2001},
	pages = {107--116},
}

@inproceedings{hoffman_dna_1997,
	title = {{DNA} visual and analytic data mining},
	booktitle = {Proceedings. {Visualization}'97 ({Cat}. {No}. {97CB36155})},
	publisher = {IEEE},
	author = {Hoffman, Patrick and Grinstein, Georges and Marx, Kenneth and Grosse, Ivo and Stanley, Eugene},
	year = {1997},
	pages = {437--441},
}

@article{grinstein_high-dimensional_2001,
	title = {High-dimensional visualization support for data mining gene expression data},
	journal = {DNA Arrays: Technologies and Experimental Strategies},
	author = {Grinstein, Georges and Jessee, C Bret and Hoffman, Patrick and O’Neil, Phil and Gee, Alexander and Grigorenko, EV},
	year = {2001},
	note = {Publisher: CRC Press LLC},
	pages = {86--131},
}

@article{daniels_properties_2012,
	title = {Properties of normalized radial visualizations},
	volume = {11},
	number = {4},
	journal = {Information Visualization},
	author = {Daniels, Karen and Grinstein, Georges and Russell, Adam and Glidden, Mason},
	year = {2012},
	note = {Publisher: Sage Publications Sage UK: London, England},
	pages = {273--300},
}

@article{lehmann_orthographic_2013,
	title = {Orthographic star coordinates},
	volume = {19},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Lehmann, Dirk J and Theisel, Holger},
	year = {2013},
	note = {Publisher: IEEE},
	pages = {2615--2624},
}

@article{rubio-sanchez_comparative_2015,
	title = {A comparative study between {RadViz} and {Star} {Coordinates}},
	volume = {22},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Rubio-Sánchez, Manuel and Raya, Laura and Diaz, Francisco and Sanchez, Alberto},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {619--628},
}

@inproceedings{shao_interactive_2017,
	title = {Interactive regression lens for exploring scatter plots},
	volume = {36},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Shao, Lin and Mahajan, Aishwarya and Schreck, Tobias and Lehmann, Dirk J},
	year = {2017},
	note = {Issue: 3},
	pages = {157--166},
}

@inproceedings{novakova_radviz_2009,
	title = {Radviz and identification of clusters in multidimensional data},
	booktitle = {2009 13th {International} {Conference} {Information} {Visualisation}},
	publisher = {IEEE},
	author = {Novakova, Lenka and Štepanková, Olga},
	year = {2009},
	pages = {104--109},
}

@inproceedings{lehmann_general_2016,
	title = {General projective maps for multidimensional data projection},
	volume = {35},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Lehmann, Dirk J and Theisel, Holger},
	year = {2016},
	note = {Issue: 2},
	pages = {443--453},
}

@inproceedings{ono_concentric_2015,
	title = {Concentric radviz: visual exploration of multi-task classification},
	booktitle = {2015 28th {SIBGRAPI} {Conference} on {Graphics}, {Patterns} and {Images}},
	publisher = {IEEE},
	author = {Ono, Jorge Henrique Piazentin and Sikansi, Fabio and Corrêa, Débora Cristina and Paulovich, Fernando Vieira and Paiva, Afonso and Nonato, Luis Gustavo},
	year = {2015},
	pages = {165--172},
}

@article{waser_world_2010,
	title = {World lines},
	volume = {16},
	number = {6},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Waser, Jurgen and Fuchs, Raphael and Ribicic, Hrvoje and Schindler, Benjamin and Bloschl, Gunther and Groller, Eduard},
	year = {2010},
	note = {Publisher: IEEE},
	pages = {1458--1467},
}

@inproceedings{heinzl_star_2017,
	title = {Star: {Visual} computing in materials science},
	volume = {36},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Heinzl, Christoph and Stappen, Stefan},
	year = {2017},
	note = {Issue: 3},
	pages = {647--666},
}

@inproceedings{inselberg_parallel_1990,
	title = {Parallel coordinates: a tool for visualizing multi-dimensional geometry},
	shorttitle = {Parallel coordinates},
	booktitle = {Proceedings of the {First} {IEEE} {Conference} on {Visualization}: {Visualization90}},
	publisher = {IEEE},
	author = {Inselberg, Alfred and Dimsdale, Bernard},
	year = {1990},
	pages = {361--378},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\PQPZBBLB\\Inselberg and Dimsdale - 1990 - Parallel coordinates a tool for visualizing multi.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\AQNGQK3G\\146402.html:text/html},
}

@article{inselberg_multidimensional_1997,
	title = {Multidimensional detective},
	language = {en},
	journal = {Proceedings Visualization},
	author = {Inselberg, A.},
	year = {1997},
	pages = {100--107},
}

@misc{a_inselberg_2009,
	title = {Inselberg {Parallel} {Coordinates}: {Visual} {Multidimensional} {Geometry} and {Its} {Applications}},
	language = {en},
	author = {{A.}},
	year = {2009},
}

@article{johansson_screen_2008,
	title = {A screen space quality method for data abstraction},
	volume = {27},
	language = {en},
	number = {3},
	journal = {Comput. Graph. Forum},
	author = {Johansson, J. and Cooper, M.},
	year = {2008},
	pages = {1039--1046},
}

@article{keim_designing_2000,
	title = {Designing pixel-oriented visualization techniques: theory and applications},
	volume = {6},
	language = {en},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Keim, D.},
	year = {2000},
	pages = {59--78},
}

@article{martens_judging_2010,
	title = {Judging correlation from scatter-plots and parallel coordinate plots},
	volume = {9},
	language = {en},
	number = {1},
	journal = {Information Visualization},
	author = {Martens, J.Li J.-B. and Wijk, J.J.},
	year = {2010},
	pages = {13--30},
}

@inproceedings{johansson_many--many_2009,
	title = {Many-to-{Many} {Relational} {Parallel} {Coordinates} {Displays}},
	language = {en},
	booktitle = {13th {International} {Conference} {Information} {Visualisation}},
	author = {Johansson, M.Lind J. and Cooper, M.},
	year = {2009},
	pages = {25--31},
}

@inproceedings{nakamura_need_1997,
	title = {The need for metrics in visual information analysis},
	language = {en},
	booktitle = {{NPIV} '97: {Proceedings} of the 1997 workshop on {New} paradigms in information visualization and manipulation},
	author = {Nakamura, N.Miller B.Hetzler G. and Whitney, P.},
	year = {1997},
	pages = {24--28},
}

@inproceedings{j-f_rit_1986,
	title = {Rit "{Propagating} temporal constraints for scheduling},
	language = {en},
	booktitle = {Proceedings of the {Fifth} {National} {Conference} on {Artificial} {Intelligence}},
	author = {{J.-F.}},
	year = {1986},
	pages = {383--388},
}

@inproceedings{sips_pixnostics_2006,
	title = {Pixnostics: {Towards} measuring the value of visualization},
	language = {en},
	booktitle = {Proceedings {Visual} {Analytics} {Science} and {Technology}},
	author = {Sips, J.Schneidewind M. and Keim, D.A.},
	year = {2006},
	pages = {199--206},
}

@article{b_shneiderman_1996,
	title = {Shneiderman "{The} eyes have it: {A} task by data type taxonomy for information visualizations},
	language = {en},
	journal = {Proceedings Visual Languages},
	author = {{B.}},
	year = {1996},
	pages = {336--343},
}

@article{magnor_combining_2009,
	title = {Combining automated analysis and visualization techniques for effective exploration of high-dimensional data},
	language = {en},
	journal = {IEEE Symposium on Visual Analytics Science and Technology},
	author = {Magnor, A.Tatu G.Albuquerque M.Eisemann H.Theisel M. and Keim, D.},
	year = {2009},
	pages = {59--66},
}

@article{rundensteiner_visual_2003,
	title = {Visual hierarchical dimension reduction for exploration of high dimensional datasets},
	language = {en},
	journal = {Proceedings Data Visualization},
	author = {Rundensteiner, J.Yang M.Ward E. and Huang, S.},
	year = {2003},
	pages = {19--28},
}

@article{cui_visual_2008,
	title = {Visual clustering in parallel coordinates},
	volume = {27},
	language = {en},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Cui, H.Zhou X.Yuan H.Qu W. and Chen, B.},
	year = {2008},
	pages = {1047--1054},
}

@inproceedings{forsell_task-based_2007,
	title = {Task-based evaluation of multirelational {3D} and standard {2D} parallel coordinates},
	language = {en},
	booktitle = {Proceedings of {SPIE}},
	author = {Forsell, C. and Johansson, J.},
	year = {2007},
	pages = {64950--64950},
}

@inproceedings{hong_effects_2008,
	title = {Effects of {Crossing} {Angles}},
	language = {en},
	booktitle = {Proceedings {Pacific} {Visualization} {Symposium}},
	author = {Hong, W.Huang S.-H. and Eades, P.},
	year = {2008},
	pages = {41--46},
}

@misc{r_tufte_2001,
	title = {Tufte {The} {Visual} {Display} of {Quantitative} {Information}},
	language = {en},
	author = {R, E.},
	year = {2001},
}

@article{allen_maintaining_1983,
	title = {Maintaining knowledge about temporal intervals},
	volume = {26},
	language = {fr},
	journal = {Communications of the ACM},
	author = {Allen, J.},
	year = {1983},
	pages = {832--843},
}

@article{eagan_low-level_2005,
	title = {Low-level components of analytic activity in information visualization},
	language = {en},
	journal = {IEEE Symposium on Information Visualization},
	author = {Eagan, R.Amar J. and Stasko, J.},
	year = {2005},
	pages = {111--117},
}

@article{andrienko_constructing_2001,
	title = {Constructing parallel coordinates plot for problem solving},
	language = {en},
	journal = {1st International Symposium on},
	author = {Andrienko, G. and Andrienko, N.},
	year = {2001},
	pages = {9--14},
}

@article{berchtold_similarity_1998,
	title = {Similarity clustering of dimensions for an enhanced visualization of multidimensional data},
	language = {en},
	journal = {Proceedings Information Visualization},
	author = {Berchtold, M.Ankerst S. and Keim, D.},
	year = {1998},
	pages = {52},
}

@book{bertini_by_2004,
	title = {By chance is not enough: {Preserving} relative density through non uniform sampling},
	language = {en},
	publisher = {Information Visualisation International Conference on},
	author = {Bertini, E. and Santucci, G.},
	year = {2004},
}

@inproceedings{bertini_visual_2006,
	title = {Visual quality metrics},
	language = {en},
	booktitle = {{BELIV} '06: {Proceedings} of the 2006 {AVI} workshop on {BEyond} time and errors},
	author = {Bertini, E. and Santucci, G.},
	year = {2006},
	pages = {1--5},
}

@article{ma_data_2009,
	title = {Data {Information} and {Knowledge} in {Visualization}},
	volume = {29},
	language = {en},
	number = {1},
	journal = {IEEE Computer Graphics and Applications},
	author = {Ma, M.Chen D.Ebert H.Hagen R.Laramee R.Van Liere K.},
	year = {2009},
	pages = {12--19},
}

@misc{cover_elements_2006,
	title = {Elements of information theory},
	language = {en},
	author = {Cover, T. and Thomas, J.},
	year = {2006},
}

@article{ellis_enabling_2006,
	title = {Enabling automatic clutter reduction in parallel coordinate plots},
	volume = {12},
	language = {en},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ellis, G. and Dix, A.},
	year = {2006},
	pages = {717--724},
}

@inproceedings{tukey_computing_1985,
	title = {Computing graphics and exploratory data analysis: {An} introduction},
	language = {en},
	booktitle = {Proceedings of the {Sixth} {Annual} {Conference} and {Exposition}: {Computer} {Graphics} 85." {Proceedings} of the {Sixth} {Annual} {Conference} and {Exposition}: {Computer} {Graphics}},
	author = {Tukey, J. and Tukey, P.},
	year = {1985},
	pages = {773--785},
}

@inproceedings{sbert_viewpoint_2001,
	title = {Viewpoint selection using viewpoint entropy},
	language = {en},
	booktitle = {Proceedings {Vision} {Modeling} and {Visualization}},
	author = {Sbert, P.Vzquez M.Feixas M. and Heidrich, W.},
	year = {2001},
	pages = {273--280},
}

@article{colpoys_cognitive_2002,
	title = {Cognitive measurements of graph aesthetics},
	volume = {1},
	language = {en},
	number = {2},
	journal = {Information Visualization},
	author = {Colpoys, C.Ware H.Purchase L. and McGill, M.},
	year = {2002},
	pages = {103--110},
}

@article{wegman_hyperdimensional_1990,
	title = {Hyperdimensional data analysis using parallel coordinates},
	language = {en},
	journal = {Journal of the American Statistical Association},
	author = {Wegman, E.},
	year = {1990},
	pages = {85},
}

@inproceedings{anand_graph-theoretic_2005,
	title = {Graph-theoretic scagnos-tics},
	language = {en},
	booktitle = {Proceedings {Information} {Visualization}},
	author = {Anand, L.Wilkinson A. and Grossman, R.},
	year = {2005},
	pages = {157--164},
}

@misc{noauthor_johansson_nodate,
	title = {Johansson: {Evaluation} of parallel coordinates: {Overview},... - {Google} {Scholar}},
	url = {https://scholar.google.com/scholar_lookup?hl=en&volume=22&publication_year=2016&pages=579-588&journal=IEEE+Trans.+Vis.+Comput.+Graph.&issue=1&author=J.+Johansson&author=C.+Forsell&title=Evaluation+of+Parallel+Coordinates%3A+Overview%2C+Categorization+and+Guidelines+for+Future+Research},
	urldate = {2022-02-24},
	file = {Johansson\: Evaluation of parallel coordinates\: Overview,... - Google Scholar:C\:\\Users\\anjul\\Zotero\\storage\\FZM5C4X2\\scholar_lookup.html:text/html},
}

@misc{noauthor_makwana_nodate,
	title = {Makwana: {Axes} re-ordering in parallel coordinate... - {Google} {Scholar}},
	url = {https://scholar.google.com/scholar_lookup?hl=en&volume=40&publication_year=2012&pages=43-48&journal=International+Journal+of+Computer+Applications&issue=13&author=H.+Makwana&author=S.+Tanwani&author=S.+Jain&title=Axes+Re%E2%80%90Ordering+in+Parallel+Coordinate+for+Pattern+Optimization},
	urldate = {2022-02-24},
	file = {Makwana\: Axes re-ordering in parallel coordinate... - Google Scholar:C\:\\Users\\anjul\\Zotero\\storage\\UGE8A684\\scholar_lookup.html:text/html},
}

@misc{makwana_axes_nodate,
	title = {Axes {Re}-ordering in {Parallel} {Coordinate} for {Pattern} {Optimization}},
	abstract = {Visualization of multidimensional dataset is a challenging task due to non-uniformity of the data. It requires new ways to display data for better analysis and interpretation. Parallel coordinate is one of the popular techniques for visualization of multi dimensional dataset. Parallel coordinate technique emphasis various types of patterns present in the dataset. Here, pattern is shown by a polyline. Slope of poly-line indicates the difference between data values. Variation in slope creates the different types of pattern. Based on slope, pattern can be classified and this kind of classification helps to explore distinct pattern available in dataset. Ordering of the axis affects pattern available in any dataset. Specific arrangement of axis may provide maximum patterns and another arrangement may provide minimum patterns. Ordering of axis in different order to find maximum or minimum pattern requires exponential time. Here, we propose a novel clustering technique using heuristic based branch \& bound based axis reordering mechanism to solve this problem in polynomial time. Keywords: Visualization, Parallel Coordinates, Cluttering, Clustering, Outlier, pattren;},
	author = {Makwana, Hemant and Tanwani, Sanjay and Jain, Suresh},
	file = {Citeseer - Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\3ANZVIBJ\\Makwana et al. - Axes Re-ordering in Parallel Coordinate for Patter.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\2EXAXZ9I\\summary.html:text/html},
}

@article{flood_traveling-salesman_1956,
	title = {The traveling-salesman problem},
	volume = {4},
	number = {1},
	journal = {Operations research},
	author = {Flood, Merrill M.},
	year = {1956},
	note = {Publisher: INFORMS},
	pages = {61--75},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\NYTLGB3R\\Flood - 1956 - The traveling-salesman problem.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\3SUIBZ5L\\opre.4.1.html:text/html},
}

@inproceedings{johansson_revealing_2005,
	title = {Revealing structure within clustered parallel coordinates displays},
	doi = {10.1109/INFVIS.2005.1532138},
	abstract = {In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.},
	booktitle = {{IEEE} {Symposium} on {Information} {Visualization}, 2005. {INFOVIS} 2005.},
	author = {Johansson, J. and Ljung, P. and Jern, M. and Cooper, M.},
	month = oct,
	year = {2005},
	note = {ISSN: 1522-404X},
	keywords = {Data analysis, Data visualization, Displays, Chromium, Data mining, Facial animation, Feedback, Information analysis, Statistics, Transfer functions},
	pages = {125--132},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\anjul\\Zotero\\storage\\N8KC7SNQ\\1532138.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\VMK7FHGE\\Johansson et al. - 2005 - Revealing structure within clustered parallel coor.pdf:application/pdf},
}

@article{lu_two_2016,
	series = {{SI}:{IVIMLA}},
	title = {Two axes re-ordering methods in parallel coordinates plots},
	volume = {33},
	issn = {1045-926X},
	url = {https://www.sciencedirect.com/science/article/pii/S1045926X15300379},
	doi = {10.1016/j.jvlc.2015.12.001},
	abstract = {Visualization and interaction of multidimensional data are challenges in visual data analytics, which requires optimized solutions to integrate the display, exploration and analytical reasoning of data into one visual pipeline for human-centered data analysis and interpretation. Even though it is considered to be one of the most popular techniques for visualization and analysis of multidimensional data, parallel coordinate visualization is also suffered from the visual clutter problem as well as the computational complexity problem, same as other visualization methods in which visual clutter occurs where the volume of data needs to be visualized to be increasing. One straightforward way to address these problems is to change the ordering of axis to reach the minimal number of visual clutters. However, the optimization of the ordering of axes is actually a NP-complete problem. In this paper, two axes re-ordering methods are proposed in parallel coordinates visualization: (1) a contribution-based method and (2) a similarity-based method. The contribution-based re-ordering method is mainly based on the singular value decomposition (SVD) algorithm. It can not only provide users with the mathmetical theory for the selection of the first remarkable axis, but also help with visualizing detailed structure of the data according to the contribution of each data dimension. This approach reduces the computational complexity greatly in comparison with other re-ordering methods. A similarity-based re-ordering method is based on the combination of nonlinear correlation coefficient (NCC) and SVD algorithms. By using this approach, axes are re-ordered in line with the degree of similarities among them. It is much more rational, exact and systemic than other re-ordering methods, including those based on Pearson’s correlation coefficient (PCC). Meanwhile, the paper also proposes a measurement of contribution rate of each dimension to reveal the property hidden in the dataset. At last, the rationale and effectiveness of these approaches are demonstrated through case studies. For example, the patterns of Smurf and Neptune attacks hidden in KDD 1999 dataset are visualized in parallel coordinates using contribution-based re-ordering method; NCC re-ordering method can enlarge the mean crossing angles and reduce the amount of polylines between the neighboring axes.},
	language = {en},
	urldate = {2022-02-26},
	journal = {Journal of Visual Languages \& Computing},
	author = {Lu, Liang Fu and Huang, Mao Lin and Zhang, Jinson},
	month = apr,
	year = {2016},
	keywords = {Axes re-ordering, Multidimensional data visualization, Nonlinear correlation coefficient, Parallel coordinates, Singular value decomposition, Visual analytics},
	pages = {3--12},
	file = {Accepted Version:C\:\\Users\\anjul\\Zotero\\storage\\SE78LRKN\\Lu et al. - 2016 - Two axes re-ordering methods in parallel coordinat.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\VRH4PSSU\\S1045926X15300379.html:text/html},
}

@inproceedings{liu_data_2018,
	address = {Montreal QC Canada},
	title = {Data {Illustrator}: {Augmenting} {Vector} {Design} {Tools} with {Lazy} {Data} {Binding} for {Expressive} {Visualization} {Authoring}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Data {Illustrator}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173697},
	doi = {10.1145/3173574.3173697},
	abstract = {Building graphical user interfaces for visualization authoring is challenging as one must reconcile the tension between ﬂexible graphics manipulation and procedural visualization generation based on a graphical grammar or declarative languages. To better support designers’ workﬂows and practices, we propose Data Illustrator, a novel visualization framework. In our approach, all visualizations are initially vector graphics; data binding is applied when necessary and only constrains interactive manipulation to that data bound property. The framework augments graphic design tools with new concepts and operators, and describes the structure and generation of a variety of visualizations. Based on the framework, we design and implement a visualization authoring system. The system extends interaction techniques in modern vector design tools for direct manipulation of visualization conﬁgurations and parameters. We demonstrate the expressive power of our approach through a variety of examples. A qualitative study shows that designers can use our framework to compose visualizations.},
	language = {en},
	urldate = {2022-02-28},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Liu, Zhicheng and Thompson, John and Wilson, Alan and Dontcheva, Mira and Delorey, James and Grigg, Sam and Kerr, Bernard and Stasko, John},
	month = apr,
	year = {2018},
	pages = {1--13},
	file = {Liu et al. - 2018 - Data Illustrator Augmenting Vector Design Tools w.pdf:C\:\\Users\\anjul\\Zotero\\storage\\54ER5F8B\\Liu et al. - 2018 - Data Illustrator Augmenting Vector Design Tools w.pdf:application/pdf},
}

@article{tyagi_user-centric_2021,
	title = {User-{Centric} {Semi}-{Automated} {Infographics} {Authoring} and {Recommendation}},
	url = {http://arxiv.org/abs/2108.11914},
	abstract = {Designing infographics can be a tedious process for non-experts and time-consuming even for professional designers. Based on the literature and a formative study, we propose a flexible framework for automated and semi-automated infographics design. This framework captures the main design components in infographics and streamlines the generation workflow into three steps, allowing users to control and optimize each aspect independently. Based on the framework, we also propose an interactive tool, {\textbackslash}name\{\}, for assisting novice designers with creating high-quality infographics from an input in a markdown format by offering recommendations of different design components of infographics. Simultaneously, more experienced designers can provide custom designs and layout ideas to the tool using a canvas to control the automated generation process partially. As part of our work, we also contribute an individual visual group (VG) and connection designs dataset (in SVG), along with a 1k complete infographic image dataset with segmented VGs. This dataset plays a crucial role in diversifying the infographic designs created by our framework. We evaluate our approach with a comparison against similar tools, a user study with novice and expert designers, and a case study. Results confirm that our framework and {\textbackslash}name\{\} excel in creating customized infographics and exploring a large variety of designs.},
	urldate = {2022-02-28},
	journal = {arXiv:2108.11914 [cs]},
	author = {Tyagi, Anjul and Zhao, Jian and Patel, Pushkar and Khurana, Swasti and Mueller, Klaus},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.11914},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\9DMRWK9L\\Tyagi et al. - 2021 - User-Centric Semi-Automated Infographics Authoring.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\KGZMKBT2\\2108.html:text/html},
}

@article{cao_ai-sketcher_2019,
	title = {{AI}-{Sketcher} : {A} {Deep} {Generative} {Model} for {Producing} {High}-{Quality} {Sketches}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{AI}-{Sketcher}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4103},
	doi = {10.1609/aaai.v33i01.33012564},
	abstract = {Sketch drawings play an important role in assisting humans in communication and creative design since ancient period. This situation has motivated the development of artificial intelligence (AI) techniques for automatically generating sketches based on user input. Sketch-RNN, a sequence-to-sequence variational autoencoder (VAE) model, was developed for this purpose and known as a state-of-the-art technique. However, it suffers from limitations, including the generation of lowquality results and its incapability to support multi-class generations. To address these issues, we introduced AI-Sketcher, a deep generative model for generating high-quality multiclass sketches. Our model improves drawing quality by employing a CNN-based autoencoder to capture the positional information of each stroke at the pixel level. It also introduces an influence layer to more precisely guide the generation of each stroke by directly referring to the training data. To support multi-class sketch generation, we provided a conditional vector that can help differentiate sketches under various classes. The proposed technique was evaluated based on two large-scale sketch datasets, and results demonstrated its power in generating high-quality sketches.},
	language = {en},
	number = {01},
	urldate = {2022-03-01},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Cao, Nan and Yan, Xin and Shi, Yang and Chen, Chaoran},
	month = jul,
	year = {2019},
	note = {Number: 01},
	pages = {2564--2571},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\TRJZ6FHH\\Cao et al. - 2019 - AI-Sketcher  A Deep Generative Model for Producin.pdf:application/pdf},
}

@misc{noauthor_sketch-rnn_nodate,
	title = {Sketch-{RNN} {Demos} by {David} {Ha}, {Jonas} {Jongejan}, {Ian} {Johnson} - {Experiments} with {Google}},
	url = {https://experiments.withgoogle.com/sketch-rnn-demo},
	abstract = {Since 2009, coders have created thousands of amazing experiments using Chrome, Android, AI, WebVR, AR and more. We're showcasing projects here, along with helpful tools and resources, to inspire others to create new experiments.},
	urldate = {2022-03-01},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\CA2PSUPI\\sketch-rnn-demo.html:text/html},
}

@article{ha_neural_2017,
	title = {A {Neural} {Representation} of {Sketch} {Drawings}},
	url = {http://arxiv.org/abs/1704.03477},
	abstract = {We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.},
	urldate = {2022-03-01},
	journal = {arXiv:1704.03477 [cs, stat]},
	author = {Ha, David and Eck, Douglas},
	month = may,
	year = {2017},
	note = {arXiv: 1704.03477},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\VR97RSZ8\\Ha and Eck - 2017 - A Neural Representation of Sketch Drawings.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\KTDTGLA8\\1704.html:text/html},
}

@article{tresset_portrait_2013,
	title = {Portrait drawing by {Paul} the robot},
	volume = {37},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849313000149},
	doi = {10.1016/j.cag.2013.01.012},
	abstract = {We describe Paul, a robotic installation that produces observational face drawings of people. Paul is a naive drawer: it does not have highlevel knowledge of the structures constitutive of the human face (such as the mouth, nose, eyes) nor the capability of learning expertise based on experience as a human would. However, Paul is able to draw using the equivalent of an artist's stylistic signature based on a number of processes mimicking drawing skills and technique, which together form a drawing cycle. Furthermore, we present here our first efforts in implementing two different versions of visual feedback to permit the robot to iteratively augment and improve a drawing which initially is built from a process of salient lines recovery. The first form of visual feedback we study we refer to as computational as it involves a purely internal (memory-based) representation of regions to render via shading by the robot. The second version we call physical as it involves the use of a camera as an ‘eye’ taking new snapshots of the artefact in progress. This is then analysed to take decisions on where and how to render shading next. A main point we emphasise in this work is the issue of embodiment of graphical systems, in our case in a robotic platform. We present our arguments in favour of such a position for the graphics community to reflect upon. Finally, we emphasise that the drawings produced by Paul have been considered of interest by fine art professionals in recent international art fairs and exhibitions, as well as by the public at large. One drawing is now in the Victoria and Albert museum collection. We identify a number of factors that may account for such perceived qualities of the produced drawings.},
	language = {en},
	number = {5},
	urldate = {2022-03-01},
	journal = {Computers \& Graphics},
	author = {Tresset, Patrick and Fol Leymarie, Frederic},
	month = aug,
	year = {2013},
	keywords = {Computer graphics, Computer vision, Fine arts, Media arts, Non-photorealistic rendering (NPR), Robotics},
	pages = {348--363},
}

@article{satyanarayan_lyra_2014,
	title = {Lyra: {An} {Interactive} {Visualization} {Design} {Environment}},
	volume = {33},
	issn = {1467-8659},
	shorttitle = {Lyra},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12391},
	doi = {10.1111/cgf.12391},
	abstract = {We present Lyra, an interactive environment for designing customized visualizations without writing code. Using drag-and-drop interactions, designers can bind data to the properties of graphical marks to author expressive visualization designs. Marks can be moved, rotated and resized using handles; relatively positioned using connectors; and parameterized by data fields using property drop zones. Lyra also provides a data pipeline interface for iterative, visual specification of data transformations and layout algorithms. Visualizations created with Lyra are represented as specifications in Vega, a declarative visualization grammar that enables sharing and reuse. We evaluate Lyra's expressivity and accessibility through diverse examples and studies with journalists and visualization designers. We find that Lyra enables users to rapidly develop customized visualizations, covering a design space comparable to existing programming-based tools.},
	language = {en},
	number = {3},
	urldate = {2022-03-01},
	journal = {Computer Graphics Forum},
	author = {Satyanarayan, Arvind and Heer, Jeffrey},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12391},
	keywords = {Categories and Subject Descriptors (according to ACM CCS):, H.5.2 Information Interfaces: User Interfaces—GUI},
	pages = {351--360},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\YB5AAP3U\\Satyanarayan and Heer - 2014 - Lyra An Interactive Visualization Design Environm.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\LN9KBQFM\\cgf.html:text/html},
}

@article{ren_ivisdesigner_2014,
	title = {{iVisDesigner}: {Expressive} {Interactive} {Design} of {Information} {Visualizations}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {{iVisDesigner}},
	url = {http://ieeexplore.ieee.org/document/6876042/},
	doi = {10.1109/TVCG.2014.2346291},
	abstract = {We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.},
	language = {en},
	number = {12},
	urldate = {2022-03-01},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ren, Donghao and Hollerer, Tobias and Yuan, Xiaoru},
	month = dec,
	year = {2014},
	pages = {2092--2101},
	file = {Ren et al. - 2014 - iVisDesigner Expressive Interactive Design of Inf.pdf:C\:\\Users\\anjul\\Zotero\\storage\\3DA78IRY\\Ren et al. - 2014 - iVisDesigner Expressive Interactive Design of Inf.pdf:application/pdf},
}

@article{kim_data-driven_2017,
	title = {Data-{Driven} {Guides}: {Supporting} {Expressive} {Design} for {Information} {Graphics}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Data-{Driven} {Guides}},
	url = {http://ieeexplore.ieee.org/document/7536218/},
	doi = {10.1109/TVCG.2016.2598620},
	abstract = {In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack ﬂexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being conﬁned by predeﬁned templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics.},
	language = {en},
	number = {1},
	urldate = {2022-03-01},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Nam Wook and Schweickart, Eston and Liu, Zhicheng and Dontcheva, Mira and Li, Wilmot and Popovic, Jovan and Pfister, Hanspeter},
	month = jan,
	year = {2017},
	pages = {491--500},
	file = {Kim et al. - 2017 - Data-Driven Guides Supporting Expressive Design f.pdf:C\:\\Users\\anjul\\Zotero\\storage\\NM27QB6V\\Kim et al. - 2017 - Data-Driven Guides Supporting Expressive Design f.pdf:application/pdf},
}

@article{vuillemot_structuring_2017,
	title = {Structuring {Visualization} {Mock}-ups at a {Graphical} {Level} by {Dividing} the {Display} {Space}},
	volume = {24},
	url = {https://hal.inria.fr/hal-01560881},
	doi = {10.1109/TVCG.2017.2743998},
	abstract = {Mock-ups are rapid, low fidelity prototypes, that are used in many design-related fields to generate and share ideas. While their creation is supported by many mature methods and tools, surprisingly little are suited for the needs of information visualization. In this article, we introduce a novel approach to creating visualizations mock-ups, based on a dialogue between graphic design and parametric toolkit explorations. Our approach consists in iteratively subdividing the display space, while progressively informing each division with realistic data. We show that a wealth of mock-ups can easily be created using only temporary data attributes, as we wait for more realistic data to become available. We describe the implementation of this approach in a D3-based toolkit, which we use to highlight its generative power, and we discuss the potential for transitioning towards higher fidelity prototypes.},
	language = {en},
	number = {1},
	urldate = {2022-03-01},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Vuillemot, Romain and Boy, Jeremy},
	month = oct,
	year = {2017},
	pages = {424},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\D766D74B\\Vuillemot and Boy - 2017 - Structuring Visualization Mock-ups at a Graphical .pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\ZEBBR2VS\\hal-01560881.html:text/html},
}

@incollection{shi_emog_2020,
	address = {New York, NY, USA},
	title = {{EmoG}: {Supporting} the {Sketching} of {Emotional} {Expressions} for {Storyboarding}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{EmoG}},
	url = {https://doi.org/10.1145/3313831.3376520},
	abstract = {Storyboarding is an important ideation technique that uses sequential art to depict important scenarios of user experience. Existing data-driven support for storyboarding focuses on constructing user stories, but fail to address its benefit as a graphic narrative device. Instead, we propose to develop a data-driven design support tool that increases the expressiveness of user stories by facilitating sketching storyboards. To explore this, we focus on supporting the sketching of emotional expressions of characters in storyboards. In this paper, we present EmoG, an interactive system that generates sketches of characters with emotional expressions based on input strokes from the user. We evaluated EmoG with 21 participants in a controlled user study. The results showed that our tool has significantly better performance in usefulness, ease of use, and quality of results than the baseline system.},
	urldate = {2022-02-28},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shi, Yang and Cao, Nan and Ma, Xiaojuan and Chen, Siji and Liu, Pei},
	month = apr,
	year = {2020},
	keywords = {creativity support tools, data-driven design, emotional expression generation, storyboarding},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\6MYIS2GW\\Shi et al. - 2020 - EmoG Supporting the Sketching of Emotional Expres.pdf:application/pdf},
}

@inproceedings{song_learning_2018,
	address = {Salt Lake City, UT},
	title = {Learning to {Sketch} with {Shortcut} {Cycle} {Consistency}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578188/},
	doi = {10.1109/CVPR.2018.00090},
	language = {en},
	urldate = {2022-03-01},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Song, Jifei and Pang, Kaiyue and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M.},
	month = jun,
	year = {2018},
	pages = {801--810},
	file = {Song et al. - 2018 - Learning to Sketch with Shortcut Cycle Consistency.pdf:C\:\\Users\\anjul\\Zotero\\storage\\7K3KFL7Y\\Song et al. - 2018 - Learning to Sketch with Shortcut Cycle Consistency.pdf:application/pdf},
}

@article{song_learning_2018-1,
	title = {Learning to {Sketch} with {Shortcut} {Cycle} {Consistency}},
	url = {https://arxiv.org/abs/1805.00247v1},
	abstract = {To see is to sketch -- free-hand sketching naturally builds ties between human and machine vision. In this paper, we present a novel approach for translating an object photo to a sketch, mimicking the human sketching process. This is an extremely challenging task because the photo and sketch domains differ significantly. Furthermore, human sketches exhibit various levels of sophistication and abstraction even when depicting the same object instance in a reference photo. This means that even if photo-sketch pairs are available, they only provide weak supervision signal to learn a translation model. Compared with existing supervised approaches that solve the problem of D(E(photo)) -{\textgreater} sketch, where E(\${\textbackslash}cdot\$) and D(\${\textbackslash}cdot\$) denote encoder and decoder respectively, we take advantage of the inverse problem (e.g., D(E(sketch)) -{\textgreater} photo), and combine with the unsupervised learning tasks of within-domain reconstruction, all within a multi-task learning framework. Compared with existing unsupervised approaches based on cycle consistency (i.e., D(E(D(E(photo)))) -{\textgreater} photo), we introduce a shortcut consistency enforced at the encoder bottleneck (e.g., D(E(photo)) -{\textgreater} photo) to exploit the additional self-supervision. Both qualitative and quantitative results show that the proposed model is superior to a number of state-of-the-art alternatives. We also show that the synthetic sketches can be used to train a better fine-grained sketch-based image retrieval (FG-SBIR) model, effectively alleviating the problem of sketch data scarcity.},
	language = {en},
	urldate = {2022-03-01},
	author = {Song, Jifei and Pang, Kaiyue and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy},
	month = may,
	year = {2018},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\2Q7BMMN6\\Song et al. - 2018 - Learning to Sketch with Shortcut Cycle Consistency.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\MQN4YV9N\\1805.html:text/html},
}

@article{li_fine-grained_nodate,
	title = {Fine-{Grained} {Sketch}-{Based} {Image} {Retrieval} by {Matching} {Deformable} {Part} {Models}},
	language = {en},
	author = {Li, Yi},
	pages = {1},
	file = {Li - Fine-Grained Sketch-Based Image Retrieval by Match.pdf:C\:\\Users\\anjul\\Zotero\\storage\\NQY3QHAB\\Li - Fine-Grained Sketch-Based Image Retrieval by Match.pdf:application/pdf},
}

@article{li_fine-grained_2014,
	title = {Fine-grained sketch-based image retrieval by matching deformable part models},
	url = {https://qmro.qmul.ac.uk/xmlui/handle/123456789/6440},
	abstract = {© 2014. The copyright of this document resides with its authors. An important characteristic of sketches, compared with text, rests with their ability to intrinsically capture object appearance and structure. Nonetheless, akin to traditional text-based image retrieval, conventional sketch-based image retrieval (SBIR) principally focuses on retrieving images of the same category, neglecting the fine-grained characteristics of sketches. In this paper, we advocate the expressiveness of sketches and examine their efficacy under a novel fine-grained SBIR framework. In particular, we study how sketches enable fine-grained retrieval within object categories. Key to this problem is introducing a mid-level sketch representation that not only captures object pose, but also possesses the ability to traverse sketch and image domains. Specifically, we learn deformable part-based model (DPM) as a mid-level representation to discover and encode the various poses in sketch and image domains independently, after which graph matching is performed on DPMs to establish pose correspondences across the two domains. We further propose an SBIR dataset that covers the unique aspects of fine-grained SBIR. Through in-depth experiments, we demonstrate the superior performance of our SBIR framework, and showcase its unique ability in fine-grained retrieval.},
	language = {en},
	urldate = {2022-03-01},
	author = {Li, Y. and Hospedales, T. M. and Song, Y. Z. and Gong, S.},
	month = jan,
	year = {2014},
	note = {Accepted: 2015-02-03T09:08:24Z},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\ZUU7HD9X\\Li et al. - 2014 - Fine-grained sketch-based image retrieval by match.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\7ZRWH3DL\\6440.html:text/html},
}

@inproceedings{simhon_sketch_2004,
	address = {Goslar, DEU},
	series = {{EGSR}'04},
	title = {Sketch interpretation and refinement using statistical models},
	isbn = {978-3-905673-12-8},
	abstract = {We present a system for generating 2D illustrations from hand drawn outlines consisting of only curve strokes. A user can draw a coarse sketch and the system would automatically augment the shape, thickness, color and surrounding texture of the curves making up the sketch. The styles for these refinements are learned from examples whose semantics have been pre-classified. There can be several styles applicable on a curve and the system automatically identifies which one to use and how to use it based on a curve's shape and its context in the illustration. Our approach is based on a Hierarchical Hidden Markov Model. We present a two level hierarchy in which the refinement process is applied at: the curve level and the scene level.},
	urldate = {2022-02-28},
	booktitle = {Proceedings of the {Fifteenth} {Eurographics} conference on {Rendering} {Techniques}},
	publisher = {Eurographics Association},
	author = {Simhon, Saul and Dudek, Gregory},
	month = jun,
	year = {2004},
	pages = {23--32},
}

@article{graves_generating_2014,
	title = {Generating {Sequences} {With} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	urldate = {2022-03-01},
	journal = {arXiv:1308.0850 [cs]},
	author = {Graves, Alex},
	month = jun,
	year = {2014},
	note = {arXiv: 1308.0850},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\9FFS5KN2\\Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\NW9LHH6H\\1308.html:text/html},
}

@article{ha_hypernetworks_2016,
	title = {{HyperNetworks}},
	url = {http://arxiv.org/abs/1609.09106},
	abstract = {This work explores hypernetworks: an approach of using a one network, also known as a hypernetwork, to generate the weights for another network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve near state-of-the-art results on a variety of sequence modelling tasks including character-level language modelling, handwriting generation and neural machine translation, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.},
	urldate = {2022-03-01},
	journal = {arXiv:1609.09106 [cs]},
	author = {Ha, David and Dai, Andrew and Le, Quoc V.},
	month = dec,
	year = {2016},
	note = {arXiv: 1609.09106},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\5FK92MSW\\Ha et al. - 2016 - HyperNetworks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\598AD3UH\\1609.html:text/html},
}

@article{zhang_drawing_2016,
	title = {Drawing and {Recognizing} {Chinese} {Characters} with {Recurrent} {Neural} {Network}},
	url = {http://arxiv.org/abs/1606.06539},
	abstract = {Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters.},
	urldate = {2022-03-01},
	journal = {arXiv:1606.06539 [cs]},
	author = {Zhang, Xu-Yao and Yin, Fei and Zhang, Yan-Ming and Liu, Cheng-Lin and Bengio, Yoshua},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.06539},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\anjul\\Zotero\\storage\\MJSMWB8M\\Zhang et al. - 2016 - Drawing and Recognizing Chinese Characters with Re.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\BYTPSSAR\\1606.html:text/html},
}

@misc{noauthor_shadowdraw_nodate,
	title = {{ShadowDraw}: real-time user guidance for freehand drawing: {ACM} {Transactions} on {Graphics}: {Vol} 30, {No} 4},
	url = {https://dl.acm.org/doi/10.1145/2010324.1964922},
	urldate = {2022-03-01},
	file = {ShadowDraw\: real-time user guidance for freehand drawing\: ACM Transactions on Graphics\: Vol 30, No 4:C\:\\Users\\anjul\\Zotero\\storage\\7YA38KG3\\2010324.html:text/html},
}

@inproceedings{zhang_context-based_2018,
	address = {New York, NY, USA},
	series = {Expressive '18},
	title = {Context-based sketch classification},
	isbn = {978-1-4503-5892-7},
	url = {https://doi.org/10.1145/3229147.3229154},
	doi = {10.1145/3229147.3229154},
	abstract = {We present a novel context-based sketch classification framework using relations extracted from scene images. Most of existing methods perform sketch classification by considering individually sketched objects and often fail to identify their correct categories, due to the highly abstract nature of sketches. For a sketched scene containing multiple objects, we propose to classify a sketched object by considering its surrounding context in the scene, which provides vital cues for alleviating its recognition ambiguity. We learn such context knowledge from a database of scene images by summarizing the inter-object relations therein, such as co-occurrence, relative positions and sizes. We show that the context information can be used for both incremental sketch classification and sketch co-classification. Our method outperforms a state-of-the-art single-object classification method, evaluated on a new dataset of sketched scenes.},
	urldate = {2022-02-28},
	booktitle = {Proceedings of the {Joint} {Symposium} on {Computational} {Aesthetics} and {Sketch}-{Based} {Interfaces} and {Modeling} and {Non}-{Photorealistic} {Animation} and {Rendering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Jianhui and Chen, Yilan and Li, Lei and Fu, Hongbo and Tai, Chiew-Lan},
	month = aug,
	year = {2018},
	keywords = {co-analysis, context, object relations, sketch classification},
	pages = {1--10},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\HTZKBZLS\\Zhang et al. - 2018 - Context-based sketch classification.pdf:application/pdf},
}

@article{chen_sketch-pix2seq_2017,
	title = {Sketch-pix2seq: a {Model} to {Generate} {Sketches} of {Multiple} {Categories}},
	shorttitle = {Sketch-pix2seq},
	abstract = {Sketch is an important media for human to communicate ideas, which reflects the superiority of human intelligence. Studies on sketch can be roughly summarized into recognition and generation. Existing models on image recognition failed to obtain satisfying performance on sketch classification. But for sketch generation, a recent study proposed a sequence-to-sequence variational-auto-encoder (VAE) model called sketch-rnn which was able to generate sketches based on human inputs. The model achieved amazing results when asked to learn one category of object, such as an animal or a vehicle. However, the performance dropped when multiple categories were fed into the model. Here, we proposed a model called sketch-pix2seq which could learn and draw multiple categories of sketches. Two modifications were made to improve the sketch-rnn model: one is to replace the bidirectional recurrent neural network (BRNN) encoder with a convolutional neural network(CNN); the other is to remove the Kullback-Leibler divergence from the objective function of VAE. Experimental results showed that models with CNN encoders outperformed those with RNN encoders in generating human-style sketches. Visualization of the latent space illustrated that the removal of KL-divergence made the encoder learn a posterior of latent space that reflected the features of different categories. Moreover, the combination of CNN encoder and removal of KL-divergence, i.e., the sketch-pix2seq model, had better performance in learning and generating sketches of multiple categories and showed promising results in creativity tasks.},
	author = {Chen, Yajing and Tu, Shikui and Yi, Yuqi and Xu, Lei},
	month = sep,
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\5LIU7VWM\\Chen et al. - 2017 - Sketch-pix2seq a Model to Generate Sketches of Mu.pdf:application/pdf},
}

@article{wang_datashot_2020,
	title = {{DataShot}: {Automatic} {Generation} of {Fact} {Sheets} from {Tabular} {Data}},
	volume = {26},
	issn = {1941-0506},
	shorttitle = {{DataShot}},
	doi = {10.1109/TVCG.2019.2934398},
	abstract = {Fact sheets with vivid graphical design and intriguing statistical insights are prevalent for presenting raw data. They help audiences understand data-related facts effectively and make a deep impression. However, designing a fact sheet requires both data and design expertise and is a laborious and time-consuming process. One needs to not only understand the data in depth but also produce intricate graphical representations. To assist in the design process, we present DataShot which, to the best of our knowledge, is the first automated system that creates fact sheets automatically from tabular data. First, we conduct a qualitative analysis of 245 infographic examples to explore general infographic design space at both the sheet and element levels. We identify common infographic structures, sheet layouts, fact types, and visualization styles during the study. Based on these findings, we propose a fact sheet generation pipeline, consisting of fact extraction, fact composition, and presentation synthesis, for the auto-generation workflow. To validate our system, we present use cases with three real-world datasets. We conduct an in-lab user study to understand the usage of our system. Our evaluation results show that DataShot can efficiently generate satisfactory fact sheets to support further customization and data presentation.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wang, Yun and Sun, Zhida and Zhang, Haidong and Cui, Weiwei and Xu, Ke and Ma, Xiaojuan and Zhang, Dongmei},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data analysis, Data visualization, Visualization, Data mining, Computer graphics, visualization, and automated design, Fact sheet, infographic, Statistical analysis},
	pages = {895--905},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\anjul\\Zotero\\storage\\2CJS8DU8\\8805442.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\PKWQ88F6\\Wang et al. - 2020 - DataShot Automatic Generation of Fact Sheets from.pdf:application/pdf},
}

@article{zhou_learning_2021,
	title = {Learning a deep motion interpolation network for human skeleton animations},
	volume = {32},
	issn = {1546-427X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2003},
	doi = {10.1002/cav.2003},
	abstract = {Motion interpolation technology produces transition motion frames between two discrete movements. It is wildly used in video games, virtual reality and augmented reality. In the fields of computer graphics and animations, our data-driven method generates transition motions of two arbitrary animations without additional control signals. In this work, we propose a novel carefully designed deep learning framework, named deep motion interpolation network (DMIN), to learn human movement habits from a real dataset and then to perform the interpolation function specific for human motions. It is a data-driven approach to capture overall rhythm of two given discrete movements and generate natural in-between motion frames. The sequence-by-sequence architecture allows completing all missing frames within single forward inference, which reduces computation time for interpolation. Experiments on human motion datasets show that our network achieves promising interpolation performance. The ablation study demonstrates the effectiveness of the carefully designed DMIN.1},
	language = {en},
	number = {3-4},
	urldate = {2022-03-01},
	journal = {Computer Animation and Virtual Worlds},
	author = {Zhou, Chi and Lai, Zhangjiong and Wang, Suzhen and Li, Lincheng and Sun, Xiaohan and Ding, Yu},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cav.2003},
	keywords = {animation, deep learning, image inpainting, motion control, motion interpolation},
	pages = {e2003},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\IHPKVIZW\\Zhou et al. - 2021 - Learning a deep motion interpolation network for h.pdf:application/pdf;Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\T7GAE2W6\\cav.html:text/html},
}

@article{tan_efficient_2018,
	title = {Efficient palette-based decomposition and recoloring of images via {RGBXY}-space geometry},
	volume = {37},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3272127.3275054},
	doi = {10.1145/3272127.3275054},
	abstract = {We introduce an extremely scalable and efficient yet simple palette-based image decomposition algorithm. Given an RGB image and set of palette colors, our algorithm decomposes the image into a set of additive mixing layers, each of which corresponds to a palette color applied with varying weight. Our approach is based on the geometry of images in RGBXY-space. This new geometric approach is orders of magnitude more efficient than previous work and requires no numerical optimization. We provide an implementation of the algorithm in 48 lines of Python code. We demonstrate a real-time layer decomposition tool in which users can interactively edit the palette to adjust the layers. After preprocessing, our algorithm can decompose 6 MP images into layers in 20 milliseconds.},
	number = {6},
	urldate = {2022-03-01},
	journal = {ACM Transactions on Graphics},
	author = {Tan, Jianchao and Echevarria, Jose and Gingold, Yotam},
	month = dec,
	year = {2018},
	keywords = {palette, color space, compositing, convex hull, generalized barycentric coordinates, images, layers, mixing, painting, recoloring, RGB},
	pages = {262:1--262:10},
	file = {Full Text:C\:\\Users\\anjul\\Zotero\\storage\\Q2YRVKKC\\Tan et al. - 2018 - Efficient palette-based decomposition and recolori.pdf:application/pdf},
}

@misc{noauthor_unmixing-based_nodate,
	title = {Unmixing-{Based} {Soft} {Color} {Segmentation} for {Image} {Manipulation} {\textbar} {ACM} {Transactions} on {Graphics}},
	url = {https://dl.acm.org/doi/10.1145/3072959.3002176},
	urldate = {2022-03-01},
	file = {Unmixing-Based Soft Color Segmentation for Image Manipulation | ACM Transactions on Graphics:C\:\\Users\\anjul\\Zotero\\storage\\IHP7IVZN\\3072959.html:text/html},
}

@article{aksoy_unmixing-based_2017,
	title = {Unmixing-{Based} {Soft} {Color} {Segmentation} for {Image} {Manipulation}},
	volume = {36},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3002176},
	doi = {10.1145/3002176},
	abstract = {We present a new method for decomposing an image into a set of soft color segments that are analogous to color layers with alpha channels that have been commonly utilized in modern image manipulation software. We show that the resulting decomposition serves as an effective intermediate image representation, which can be utilized for performing various, seemingly unrelated, image manipulation tasks. We identify a set of requirements that soft color segmentation methods have to fulfill, and present an in-depth theoretical analysis of prior work. We propose an energy formulation for producing compact layers of homogeneous colors and a color refinement procedure, as well as a method for automatically estimating a statistical color model from an image. This results in a novel framework for automatic and high-quality soft color segmentation that is efficient, parallelizable, and scalable. We show that our technique is superior in quality compared to previous methods through quantitative analysis as well as visually through an extensive set of examples. We demonstrate that our soft color segments can easily be exported to familiar image manipulation software packages and used to produce compelling results for numerous image manipulation applications without forcing the user to learn new tools and workflows.},
	language = {en},
	number = {2},
	urldate = {2022-03-01},
	journal = {ACM Transactions on Graphics},
	author = {Aksoy, Yağiz and Aydin, Tunç Ozan and Smolić, Aljoša and Pollefeys, Marc},
	month = apr,
	year = {2017},
	pages = {1--19},
	file = {Aksoy et al. - 2017 - Unmixing-Based Soft Color Segmentation for Image M.pdf:C\:\\Users\\anjul\\Zotero\\storage\\BNRZ7WCJ\\Aksoy et al. - 2017 - Unmixing-Based Soft Color Segmentation for Image M.pdf:application/pdf},
}

@article{aksoy_unmixing-based_2017-1,
	title = {Unmixing-{Based} {Soft} {Color} {Segmentation} for {Image} {Manipulation}},
	doi = {10.1145/3002176},
	abstract = {A new method for decomposing an image into a set of soft color segments that are analogous to color layers with alpha channels that have been commonly utilized in modern image manipulation software is presented. We present a new method for decomposing an image into a set of soft color segments that are analogous to color layers with alpha channels that have been commonly utilized in modern image manipulation software. We show that the resulting decomposition serves as an effective intermediate image representation, which can be utilized for performing various, seemingly unrelated, image manipulation tasks. We identify a set of requirements that soft color segmentation methods have to fulfill, and present an in-depth theoretical analysis of prior work. We propose an energy formulation for producing compact layers of homogeneous colors and a color refinement procedure, as well as a method for automatically estimating a statistical color model from an image. This results in a novel framework for automatic and high-quality soft color segmentation that is efficient, parallelizable, and scalable. We show that our technique is superior in quality compared to previous methods through quantitative analysis as well as visually through an extensive set of examples. We demonstrate that our soft color segments can easily be exported to familiar image manipulation software packages and used to produce compelling results for numerous image manipulation applications without forcing the user to learn new tools and workflows.},
	journal = {TOGS},
	author = {Aksoy, Yagiz and Aydin, T. and Smolic, A. and Pollefeys, M.},
	year = {2017},
}

@article{wang_data-driven_2010,
	title = {Data-driven image color theme enhancement},
	volume = {29},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/1882261.1866172},
	doi = {10.1145/1882261.1866172},
	abstract = {It is often important for designers and photographers to convey or enhance desired color themes in their work. A color theme is typically defined as a template of colors and an associated verbal description. This paper presents a data-driven method for enhancing a desired color theme in an image. We formulate our goal as a unified optimization that simultaneously considers a desired color theme, texture-color relationships as well as automatic or user-specified color constraints. Quantifying the difference between an image and a color theme is made possible by color mood spaces and a generalization of an additivity relationship for two-color combinations. We incorporate prior knowledge, such as texture-color relationships, extracted from a database of photographs to maintain a natural look of the edited images. Experiments and a user study have confirmed the effectiveness of our method.},
	number = {6},
	urldate = {2022-03-01},
	journal = {ACM Transactions on Graphics},
	author = {Wang, Baoyuan and Yu, Yizhou and Wong, Tien-Tsin and Chen, Chun and Xu, Ying-Qing},
	month = dec,
	year = {2010},
	keywords = {color optimization, color theme, histograms, soft segmentation, texture classes},
	pages = {146:1--146:10},
	file = {Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\PIP8S7FR\\Wang et al. - 2010 - Data-driven image color theme enhancement.pdf:application/pdf},
}

@article{kim_image_2017,
	title = {Image color adjustment for harmony with a target color},
	volume = {43},
	doi = {10.1002/col.22144},
	abstract = {Although a number of methods have been developed for image adjustment in various applications, very little work has been done in the context of visual design. In this regard, this article introduces a novel and practical context of image color adjustment and develops a method to adjust an image for harmony with a target color. The experiment with designers revealed that designers made significant changes in hue dimension, and preferred to promote color similarity between the image and the target color. Based on insights from designers, we proposed a method to achieve a harmonious combination of an image and a color element by increasing the hue similarity between them. The result of a user test revealed that our method is particularly useful for images with nonliving objects but less effective for images involving human skin, foods, and so on. It is expected that the practical context investigated in this study can promote a variety of related studies that satisfy the tangible needs of industries and academia.},
	journal = {Color Research \& Application},
	author = {Kim, EunJin and Suk, Hyeon-Jeong},
	month = may,
	year = {2017},
}

@inproceedings{endo_deepprop_2016,
	title = {Deepprop: {Extracting} deep features from a single image for edit propagation},
	volume = {35},
	shorttitle = {Deepprop},
	booktitle = {Computer {Graphics} {Forum}},
	publisher = {Wiley Online Library},
	author = {Endo, Yuki and Iizuka, Satoshi and Kanamori, Yoshihiro and Mitani, Jun},
	year = {2016},
	note = {Issue: 2},
	pages = {189--201},
	file = {Snapshot:C\:\\Users\\anjul\\Zotero\\storage\\HM933N7L\\cgf.html:text/html},
}

@article{byrne_acquired_2016,
	title = {Acquired {Codes} of {Meaning} in {Data} {Visualization} and {Infographics}: {Beyond} {Perceptual} {Primitives}},
	volume = {22},
	issn = {1941-0506},
	shorttitle = {Acquired {Codes} of {Meaning} in {Data} {Visualization} and {Infographics}},
	doi = {10.1109/TVCG.2015.2467321},
	abstract = {While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88\% of the infographics and 71\% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Byrne, Lydia and Angus, Daniel and Wiles, Janet},
	month = jan,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data visualization, Visualization, Encoding, Image color analysis, Illustrative Visualization, Shape, Context, Design Methodologies, Taxonomies, Visual Design},
	pages = {509--518},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\anjul\\Zotero\\storage\\HQR2E57V\\7192636.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\anjul\\Zotero\\storage\\KMLRDWKK\\Byrne et al. - 2016 - Acquired Codes of Meaning in Data Visualization an.pdf:application/pdf},
}
